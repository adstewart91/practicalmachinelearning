---
Author: "Andrew D. Stewart"
title: "Prediction Assignment Writeup"
output: 
  html_document:
    keep_md: true
    
---
## Synopsis: 
This analysis examines the data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.  This project's goal is to use the data from the sensors to train a model that can predict how well the activity was performed.

### Data
The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  
  
The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv  
  
The data for this project come from this source:
http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har.  


## What You Should Submit: (Quoted from Assignment)
(1) You should create a report describing how you built your model, 
(2) how you used cross validation, 
(3) what you think the expected out of sample error is, and 
(4) why you made the choices you did. 
(5) You will also use your prediction model to predict 20 different test cases.
  

## Load Libraries and Set Defaults
This section loads R Libraries, sets knitr defaults for output, and sets a random seed (4891) to support reproducabilty.  See markdown file for actual code.
```{r libraries, echo=FALSE, results="hide", message=FALSE, warning = FALSE}

library(caret)
library(data.table)
library(dplyr)
library(lubridate)
library(ggplot2)
library(datasets)
library(xtable)
library(pander)
library(rpart)
library(randomForest)
library(parallel)
library(doParallel)
library(rgl)
library(knitr)
library(kableExtra)
library(htmlTable)

knitr::opts_chunk$set(echo = TRUE, results = "asis")
knit_hooks$set(webgl = hook_webgl)

## Center Justify All Plot Titles for ggplot
theme_update(plot.title = element_text(hjust = 0.5))

## Random Seed
set.seed(4891)

```

## Question 1  
### Part a - Loading and Preprocessing the Data  
First the Training data for the model must be read in from the data sources identified above.  Next, *all columns* of the data that contain sensor-subject summary data (kurtosis, skewness, max, min, amplitude, var, avg, stddev) are removed since my approach was to use only the actual sensor data.  The first seven (7) columns were also removed as they contained identifying information (e.g.: subject name) that were also not relevant for a model based on sensor data.  

Finally, the Training data was partitioned into two sets (70% / 30%) to support model development on the first set (70%) and *Cross Validation* on the second set (30%).

```{r Load Testing and Training Data, echo = TRUE, results = "markup"}

## Read activity.csv and format as tbl_df
actyTrainData <- read.csv("pml-training.csv", header = TRUE)
actyTrainData <- tbl_df(actyTrainData)

## Make a copy to use to partition
traindata <- tbl_df(actyTrainData)

## Read Column names
keepcolnames <-colnames(traindata)

## Create vector of column names to keep (remove summary statistic column names)
names_vector <- !(grepl("^(kurtosis)",keepcolnames) | grepl("^(skewness)",keepcolnames) | grepl("^(max)",keepcolnames) | grepl("^(min)",keepcolnames) | grepl("^(amplitude)",keepcolnames)| grepl("^(var)",keepcolnames) | grepl("^(avg)",keepcolnames) | grepl("^(stddev)",keepcolnames) )

## Select only column names with senor data
filtertraindata <- select(traindata,keepcolnames[names_vector])

## Remove first seven (7) columns of non-sensor data
filtertraindata <- select(filtertraindata,-c(1:7))

## Partition the Traing data into two Training sets for cross-validation
inTrain = createDataPartition(y=filtertraindata$classe, p = 0.7,list=FALSE)
training1 = filtertraindata[inTrain,]
training2 = filtertraindata[-inTrain,]
```

## Question 1  
### Part b - Train the Model as Random Forest
```{r Traing Model, echo = TRUE, cache = TRUE, results = "markup"}
## Parallel Cluster Code from Class Forum/Discusson on methods using Parallel Processing:
## Class Forum notes references the following github repo:
## https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md

## Also, had to use: devtools::install_github('topepo/caret/pkg/caret') to update caret

## Set up Parallel Cluster  -- Allow one (1) core for MAC-OS:
cluster <- makeCluster(detectCores() - 1) 
registerDoParallel(cluster)

## Set Training Control Parameters:
fitControl <- trainControl(method = "oob",number = 10, allowParallel = TRUE)

## Fit Classe to all Sensor data:
fit2 <- train(classe ~. , method="rf",data=training1, trControl = fitControl, importance = TRUE)

## Stop parallel processing cluster
stopCluster(cluster)
registerDoSEQ()
```

## Question 2 - Perform Model Review and Cross Validation:

```{r Review and Cross Validation, echo = TRUE, results = "markup" }

## Model Review
## Compare 1st Training Set with Model Predictions
conMatrix <- confusionMatrix(training1$classe, fit2$finalModel$predicted)
print(conMatrix)

## Cross-Validate Model with 2nd Training Set:
predictTrain2 <- predict(fit2, newdata=training2)
conMatrix <- confusionMatrix(predictTrain2, training2$classe)
print(conMatrix)
```

## Question 3 - Expected Out of Sample Error


```{r}

## out of bag error estimates
mean(fit2$finalModel$err.rate[,"OOB"])


```

## Question 4 - Model Choice Review
### And, Plots of Training Data


```{r Plots, webgl=TRUE, echo = FALSE, results = "markup" }

## Plots
## plot(fit2,main="Accuracy by Predictor Count")
varImpPlot(fit2$finalModel, main="Variable Importance Plot")

qplot(roll_belt, yaw_belt, color=classe, data=training1, main="Training Set roll_belt and yaw_belt")

qplot(roll_belt, pitch_belt, color=classe, data=training1, main="Training Set roll_belt and pitch_belt")

qplot(roll_belt, magnet_dumbbell_z, color=classe, data=training1, main="Training Set roll_belt and magnet_dumbbell_z")

threeDplot <- with(training1, plot3d(pitch_belt, roll_belt, yaw_belt, col = (as.numeric(classe)+1), pch=19, main="Rotate-able 3D Plot of Training Set for pitch_belt, roll_belt, yaw_belt by Classe Type", sub="***** Use Mouse/Cursor to Zoom, Move, and Rotate *****"))

legend3d("right", pch = 19, yjust=0, cex=0.75, legend = levels(training1$classe), col = (1 + seq_along(levels(training1$classe))))

```


## Question 5 - Model Prediction Against Test Set
```{r Prediction of Test Data, echo = TRUE, results = "markup"}
## Read and Filter Test Data:
actyTestData <- read.csv("pml-testing.csv", header = TRUE)
actyTestData <- tbl_df(actyTestData)
testdata <- tbl_df(actyTestData)  ## Makes a copy

## Filter out columns to match Training Set
keepcolnamesT <-colnames(testdata)
names_vectorT <- !(grepl("^(kurtosis)",keepcolnamesT) | grepl("^(skewness)",keepcolnamesT) | grepl("^(max)",keepcolnamesT) | grepl("^(min)",keepcolnamesT) | grepl("^(amplitude)",keepcolnamesT)| grepl("^(var)",keepcolnamesT) | grepl("^(avg)",keepcolnamesT) | grepl("^(stddev)",keepcolnamesT) )

## Keep only Sensor Columns:
filtertestdata <- select(testdata,keepcolnamesT[names_vectorT])
filtertestdata <- select(filtertestdata,-c(1:7))

## Run Prediction on Test Set using model:
pred <- predict(fit2,filtertestdata)
pred <- tbl_df(pred)
pandoc.table(pred, style = "rmarkdown")
## Results Submitted to Quiz -- 100%!!

```
## Located at:

https://adstewart91.github.io/practicalmachinelearning/Prediction_Assignment.html

https://htmlpreview.github.io/?https://adstewart91.github.io/practicalmachinelearning/Prediction_Assignment.html
