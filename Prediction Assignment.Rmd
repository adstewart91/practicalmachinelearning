---
Author: "Andrew D. Stewart"
title: "Prediction Assignment Writeup"
output: 
  html_document:
    keep_md: true
---
## Synopsis: 
This analysis examines the data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.  This project's goal is to use the data from the sensors to train a model that can predict how well the activity was performed.

### Data
The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  
  
The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv  
  
The data for this project come from this source:
http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har.  
  

## Load Libraries
```{r libraries, echo=FALSE, results="hide", message=FALSE, warning = FALSE}
library(caret)
library(data.table)
library(dplyr)
library(lubridate)
library(ggplot2)
library(datasets)
library(xtable)
library(pander)
library(rpart)
library(randomForest)
library(parallel)
library(doParallel)
library(rgl)
library(knitr)
library(kableExtra)
library(htmlTable)

```


## Loading and Preprocessing the Data

```{r Load Testing and Training Data, echo = TRUE, results = "markup"}
knitr::opts_chunk$set(echo = TRUE, results = "asis")
knit_hooks$set(webgl = hook_webgl)

## Center Justify All Plot Titles for ggplot
theme_update(plot.title = element_text(hjust = 0.5))

## Read activity.csv and format as tbl_df
actyTrainData <- read.csv("pml-training.csv", header = TRUE)
actyTrainData <- tbl_df(actyTrainData)

## Make a copy to use to partition
traindata <- tbl_df(actyTrainData)

## Read Column names
keepcolnames <-colnames(traindata)

## Create vector of column names to keep (remove summary statistic column names)
names_vector <- !(grepl("^(kurtosis)",keepcolnames) | grepl("^(skewness)",keepcolnames) | grepl("^(max)",keepcolnames) | grepl("^(min)",keepcolnames) | grepl("^(amplitude)",keepcolnames)| grepl("^(var)",keepcolnames) | grepl("^(avg)",keepcolnames) | grepl("^(stddev)",keepcolnames) )

## Select only column names with senor data
filtertraindata <- select(traindata,keepcolnames[names_vector])

## Remove first seven (7) columns of non-sensor data
filtertraindata <- select(filtertraindata,-c(1:7))

## Partition the Traing data into two Training sets for cross-validation
inTrain = createDataPartition(y=filtertraindata$classe, p = 0.7,list=FALSE)
training1 = filtertraindata[inTrain,]
training2 = filtertraindata[-inTrain,]
```


## Train the Model as Random Forest
```{r Traing Model, echo = TRUE, cache = TRUE, results = "markup"}
## Parallel Cluster Code from Class Forum/Discusson on methods using Parallel Processing:
## Class Forum notes references the following github repo:
## https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md

## Also, had to use: devtools::install_github('topepo/caret/pkg/caret') to update caret

## Set up Parallel Cluster  -- Allow one (1) core for MAC-OS:
cluster <- makeCluster(detectCores() - 1) 
registerDoParallel(cluster)

## Set Training Control Parameters:
fitControl <- trainControl(method = "oob",number = 10, allowParallel = TRUE)

## Fit Classe to all Sensor data:
fit2 <- train(classe ~. , method="rf",data=training1, trControl = fitControl, importance = TRUE)

## Stop parallel processing cluster
stopCluster(cluster)
registerDoSEQ()
```

## Perform Model Review and Cross Validation:

```{r Review and Cross Validation, echo = TRUE, results = "markup" }

## Model Review
## Compare 1st Training Set with Model Predictions
conMatrix <- confusionMatrix(training1$classe, fit2$finalModel$predicted)
print(conMatrix)

## out of bag error estimates
mean(fit2$finalModel$err.rate[,"OOB"])

## Cross-Validate Model with 2nd Training Set:
predictTrain2 <- predict(fit2, newdata=training2)
conMatrix <- confusionMatrix(predictTrain2, training2$classe)
print(conMatrix)


```

## Plots of Training Data
```{r Plots, webgl=TRUE, echo = FALSE, results = "markup" }

## Plots
## plot(fit2,main="Accuracy by Predictor Count")
varImpPlot(fit2$finalModel, main="Variable Importance Plot")

qplot(roll_belt, yaw_belt, color=classe, data=training1, main="Training Set roll_belt and yaw_belt")

qplot(roll_belt, pitch_belt, color=classe, data=training1, main="Training Set roll_belt and pitch_belt")

qplot(roll_belt, magnet_dumbbell_z, color=classe, data=training1, main="Training Set roll_belt and magnet_dumbbell_z")

##threeDplot <- with(training1, plot3d(pitch_belt, roll_belt, yaw_belt, col = (as.numeric(classe)+1), pch=19, main="Rotate-able 3D Plot of Training Set for pitch_belt, roll_belt, yaw_belt by Classe Type", sub="** Use Mouse/Cursor to Move and Rotate **"))

##legend3d("right", pch = 19, yjust=0, cex=0.75, legend = levels(training1$classe), col = (1 + seq_along(levels(training1$classe))))

```


## Model Prediction Against Test Set

```{r Prediction of Test Data, echo = TRUE, results = "markup"}
## Read and Filter Test Data:
actyTestData <- read.csv("pml-testing.csv", header = TRUE)
actyTestData <- tbl_df(actyTestData)
testdata <- tbl_df(actyTestData)  ## Makes a copy

## Filter out columns to match Training Set
keepcolnamesT <-colnames(testdata)
names_vectorT <- !(grepl("^(kurtosis)",keepcolnamesT) | grepl("^(skewness)",keepcolnamesT) | grepl("^(max)",keepcolnamesT) | grepl("^(min)",keepcolnamesT) | grepl("^(amplitude)",keepcolnamesT)| grepl("^(var)",keepcolnamesT) | grepl("^(avg)",keepcolnamesT) | grepl("^(stddev)",keepcolnamesT) )

## Keep only Sensor Columns:
filtertestdata <- select(testdata,keepcolnamesT[names_vectorT])
filtertestdata <- select(filtertestdata,-c(1:7))

## Run Prediction on Test Set using model:
pred <- predict(fit2,filtertestdata)
pred <- tbl_df(pred)
pandoc.table(pred, style = "rmarkdown")
## Results Submitted to Quiz -- 100%!!

```
